{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb8d8f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "import utils\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, arch, classifier, epoch, dataloader, device=\"cpu\", status=\"validation\"):\n",
    "    model.eval()\n",
    "    classifier.eval()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    total_correct = 0\n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, (inp, target) in enumerate(dataloader, start=1):\n",
    "            inp = inp.to(device)\n",
    "            target = target.to(device)\n",
    "            batch_size = inp.size(0)\n",
    "\n",
    "            # Forward pass\n",
    "            if \"vit\" in arch:\n",
    "                intermediate_output = model.get_intermediate_layers(inp, 1)\n",
    "                output_features = torch.cat([x[:, 0] for x in intermediate_output], dim=-1)\n",
    "                avg_pooled = torch.mean(intermediate_output[-1][:, 1:], dim=1)\n",
    "                output_features = torch.cat((output_features, avg_pooled), dim=-1)\n",
    "            else:\n",
    "                output_features = model(inp)\n",
    "            output = classifier(output_features)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = nn.CrossEntropyLoss()(output, target)\n",
    "\n",
    "            # Accumulate loss and samples\n",
    "            total_loss += loss.item() * batch_size\n",
    "            total_samples += batch_size\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, pred = torch.max(output, dim=1)\n",
    "            total_correct += pred.eq(target).sum().item()\n",
    "\n",
    "            # Accumulate outputs and targets for F1-score computation\n",
    "            all_outputs.append(output.cpu())\n",
    "            all_targets.append(target.cpu())\n",
    "\n",
    "    # Compute average loss and accuracy\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc = 100.0 * total_correct / total_samples\n",
    "\n",
    "    # Concatenate all outputs and targets\n",
    "    all_outputs = torch.cat(all_outputs)\n",
    "    all_targets = torch.cat(all_targets)\n",
    "\n",
    "    # Compute F1-score\n",
    "    avg_f1 = utils.f1_score(all_outputs, all_targets, classifier.num_labels)\n",
    "\n",
    "    # Log statistics\n",
    "    val_stat = {\n",
    "        'val_loss': avg_loss,\n",
    "        'val_acc1': avg_acc,\n",
    "        'val_f1': avg_f1\n",
    "    }\n",
    "    if status == \"validation\":\n",
    "        print(\n",
    "            \"[VALID] \"\n",
    "            f\"epoch: {epoch + 1:03d} | \"\n",
    "            f\"valid acc: {val_stat['val_acc1']:05.2f} | \"\n",
    "            f\"valid f1: {val_stat['val_f1']:.4f}\"\n",
    "        )\n",
    "    elif status == \"test\":\n",
    "        print(\n",
    "            \"[TEST] \"\n",
    "            f\"test acc: {val_stat['val_acc1']:05.2f} | \"\n",
    "            f\"test f1: {val_stat['val_f1']:.4f}\"\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(\"Set the valid status. Avaliable status is \\\"validation\\\" or \\\"test\\\".\")\n",
    "    return val_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef07c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear classifier training setting using DINO-pretrained ResNet-50 as backbone\n",
    "\n",
    "MODEL_NAME = \"resnet50\"\n",
    "SSL_METHOD = \"DINO\"\n",
    "GPU_NUM = 1\n",
    "\n",
    "num_labels = 39\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "lr = 1e-4\n",
    "log_interval = 10\n",
    "\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c9e7e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ok] Loaded cleanly: LeafVision_DINO_resnet50.pth\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model and classifier for plant disease classification.\n",
    "\n",
    "model, classifier = utils.init_pretrained_model(MODEL_NAME, SSL_METHOD, num_labels=num_labels, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "163de95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement your plant disease dataset/dataloader, optimizer, and scheduler (optional) here.\n",
    "\n",
    "train_dataset_path = \"./dataset/PV/05images/train\"\n",
    "valid_dataset_path = \"./dataset/PV/05images/valid\"\n",
    "test_dataset_path = \"./dataset/PV/test\"\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4371, 0.5177, 0.3476), (0.1789, 0.1545, 0.1923)),\n",
    "])\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(256, interpolation=3),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4371, 0.5177, 0.3476), (0.1789, 0.1545, 0.1923)),\n",
    "])\n",
    "\n",
    "train_set = datasets.ImageFolder(train_dataset_path, transform=train_transform)\n",
    "valid_set = datasets.ImageFolder(valid_dataset_path, transform=test_transform)\n",
    "test_set = datasets.ImageFolder(test_dataset_path, transform=test_transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_set, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    params=[\n",
    "        {'params': classifier.parameters(), 'lr': lr}\n",
    "    ],\n",
    "    lr=lr\n",
    ")\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs, eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c16ea4f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRAIN] epoch: 001 | train acc: 00.51 | train f1: 0.0011\n",
      "[VALID] epoch: 001 | valid acc: 02.56 | valid f1: 0.0114\n",
      "Finished training 1 epoch\n",
      "[TRAIN] epoch: 002 | train acc: 04.62 | train f1: 0.0359\n",
      "[VALID] epoch: 002 | valid acc: 05.13 | valid f1: 0.0556\n",
      "Finished training 2 epoch\n",
      "[TRAIN] epoch: 003 | train acc: 10.77 | train f1: 0.0651\n",
      "[VALID] epoch: 003 | valid acc: 10.26 | valid f1: 0.0893\n",
      "Finished training 3 epoch\n",
      "[TRAIN] epoch: 004 | train acc: 09.23 | train f1: 0.0629\n",
      "[VALID] epoch: 004 | valid acc: 07.69 | valid f1: 0.0614\n",
      "Finished training 4 epoch\n",
      "[TRAIN] epoch: 005 | train acc: 08.72 | train f1: 0.0749\n",
      "[VALID] epoch: 005 | valid acc: 07.69 | valid f1: 0.0613\n",
      "Finished training 5 epoch\n",
      "[TRAIN] epoch: 006 | train acc: 07.18 | train f1: 0.0570\n",
      "[VALID] epoch: 006 | valid acc: 07.69 | valid f1: 0.0613\n",
      "Finished training 6 epoch\n",
      "[TRAIN] epoch: 007 | train acc: 07.69 | train f1: 0.0664\n",
      "[VALID] epoch: 007 | valid acc: 12.82 | valid f1: 0.1212\n",
      "Finished training 7 epoch\n",
      "[TRAIN] epoch: 008 | train acc: 16.92 | train f1: 0.1920\n",
      "[VALID] epoch: 008 | valid acc: 14.10 | valid f1: 0.1298\n",
      "Finished training 8 epoch\n",
      "[TRAIN] epoch: 009 | train acc: 28.72 | train f1: 0.3297\n",
      "[VALID] epoch: 009 | valid acc: 28.21 | valid f1: 0.2873\n",
      "Finished training 9 epoch\n",
      "[TRAIN] epoch: 010 | train acc: 49.74 | train f1: 0.5573\n",
      "[VALID] epoch: 010 | valid acc: 41.03 | valid f1: 0.4168\n",
      "Finished training 10 epoch\n",
      "[TRAIN] epoch: 011 | train acc: 58.97 | train f1: 0.6315\n",
      "[VALID] epoch: 011 | valid acc: 53.85 | valid f1: 0.5456\n",
      "Finished training 11 epoch\n",
      "[TRAIN] epoch: 012 | train acc: 68.21 | train f1: 0.7289\n",
      "[VALID] epoch: 012 | valid acc: 60.26 | valid f1: 0.6049\n",
      "Finished training 12 epoch\n",
      "[TRAIN] epoch: 013 | train acc: 72.82 | train f1: 0.7570\n",
      "[VALID] epoch: 013 | valid acc: 62.82 | valid f1: 0.6393\n",
      "Finished training 13 epoch\n",
      "[TRAIN] epoch: 014 | train acc: 74.36 | train f1: 0.7534\n",
      "[VALID] epoch: 014 | valid acc: 69.23 | valid f1: 0.6913\n",
      "Finished training 14 epoch\n",
      "[TRAIN] epoch: 015 | train acc: 79.49 | train f1: 0.8180\n",
      "[VALID] epoch: 015 | valid acc: 70.51 | valid f1: 0.7085\n",
      "Finished training 15 epoch\n",
      "[TRAIN] epoch: 016 | train acc: 82.05 | train f1: 0.8457\n",
      "[VALID] epoch: 016 | valid acc: 71.79 | valid f1: 0.7015\n",
      "Finished training 16 epoch\n",
      "[TRAIN] epoch: 017 | train acc: 86.15 | train f1: 0.8714\n",
      "[VALID] epoch: 017 | valid acc: 73.08 | valid f1: 0.7165\n",
      "Finished training 17 epoch\n",
      "[TRAIN] epoch: 018 | train acc: 88.72 | train f1: 0.8962\n",
      "[VALID] epoch: 018 | valid acc: 75.64 | valid f1: 0.7411\n",
      "Finished training 18 epoch\n",
      "[TRAIN] epoch: 019 | train acc: 88.21 | train f1: 0.8942\n",
      "[VALID] epoch: 019 | valid acc: 76.92 | valid f1: 0.7530\n",
      "Finished training 19 epoch\n",
      "[TRAIN] epoch: 020 | train acc: 88.72 | train f1: 0.8958\n",
      "[VALID] epoch: 020 | valid acc: 76.92 | valid f1: 0.7530\n",
      "Finished training 20 epoch\n",
      "[TRAIN] epoch: 021 | train acc: 90.77 | train f1: 0.9095\n",
      "[VALID] epoch: 021 | valid acc: 78.21 | valid f1: 0.7578\n",
      "Finished training 21 epoch\n",
      "[TRAIN] epoch: 022 | train acc: 90.77 | train f1: 0.9146\n",
      "[VALID] epoch: 022 | valid acc: 78.21 | valid f1: 0.7578\n",
      "Finished training 22 epoch\n",
      "[TRAIN] epoch: 023 | train acc: 91.79 | train f1: 0.9216\n",
      "[VALID] epoch: 023 | valid acc: 78.21 | valid f1: 0.7578\n",
      "Finished training 23 epoch\n",
      "[TRAIN] epoch: 024 | train acc: 93.33 | train f1: 0.9337\n",
      "[VALID] epoch: 024 | valid acc: 79.49 | valid f1: 0.7754\n",
      "Finished training 24 epoch\n",
      "[TRAIN] epoch: 025 | train acc: 94.87 | train f1: 0.9495\n",
      "[VALID] epoch: 025 | valid acc: 82.05 | valid f1: 0.8051\n",
      "Finished training 25 epoch\n",
      "[TRAIN] epoch: 026 | train acc: 92.31 | train f1: 0.9239\n",
      "[VALID] epoch: 026 | valid acc: 84.62 | valid f1: 0.8281\n",
      "Finished training 26 epoch\n",
      "[TRAIN] epoch: 027 | train acc: 94.36 | train f1: 0.9454\n",
      "[VALID] epoch: 027 | valid acc: 84.62 | valid f1: 0.8281\n",
      "Finished training 27 epoch\n",
      "[TRAIN] epoch: 028 | train acc: 93.33 | train f1: 0.9345\n",
      "[VALID] epoch: 028 | valid acc: 84.62 | valid f1: 0.8281\n",
      "Finished training 28 epoch\n",
      "[TRAIN] epoch: 029 | train acc: 96.92 | train f1: 0.9697\n",
      "[VALID] epoch: 029 | valid acc: 84.62 | valid f1: 0.8281\n",
      "Finished training 29 epoch\n",
      "[TRAIN] epoch: 030 | train acc: 93.85 | train f1: 0.9382\n",
      "[VALID] epoch: 030 | valid acc: 85.90 | valid f1: 0.8376\n",
      "Finished training 30 epoch\n",
      "[TRAIN] epoch: 031 | train acc: 94.87 | train f1: 0.9518\n",
      "[VALID] epoch: 031 | valid acc: 85.90 | valid f1: 0.8376\n",
      "Finished training 31 epoch\n",
      "[TRAIN] epoch: 032 | train acc: 95.38 | train f1: 0.9562\n",
      "[VALID] epoch: 032 | valid acc: 85.90 | valid f1: 0.8376\n",
      "Finished training 32 epoch\n",
      "[TRAIN] epoch: 033 | train acc: 95.38 | train f1: 0.9540\n",
      "[VALID] epoch: 033 | valid acc: 85.90 | valid f1: 0.8376\n",
      "Finished training 33 epoch\n",
      "[TRAIN] epoch: 034 | train acc: 94.87 | train f1: 0.9504\n",
      "[VALID] epoch: 034 | valid acc: 85.90 | valid f1: 0.8376\n",
      "Finished training 34 epoch\n",
      "[TRAIN] epoch: 035 | train acc: 94.87 | train f1: 0.9511\n",
      "[VALID] epoch: 035 | valid acc: 85.90 | valid f1: 0.8376\n",
      "Finished training 35 epoch\n",
      "[TRAIN] epoch: 036 | train acc: 94.36 | train f1: 0.9452\n",
      "[VALID] epoch: 036 | valid acc: 85.90 | valid f1: 0.8376\n",
      "Finished training 36 epoch\n",
      "[TRAIN] epoch: 037 | train acc: 95.38 | train f1: 0.9559\n",
      "[VALID] epoch: 037 | valid acc: 85.90 | valid f1: 0.8376\n",
      "Finished training 37 epoch\n",
      "[TRAIN] epoch: 038 | train acc: 95.38 | train f1: 0.9551\n",
      "[VALID] epoch: 038 | valid acc: 85.90 | valid f1: 0.8376\n",
      "Finished training 38 epoch\n",
      "[TRAIN] epoch: 039 | train acc: 96.92 | train f1: 0.9703\n",
      "[VALID] epoch: 039 | valid acc: 85.90 | valid f1: 0.8376\n",
      "Finished training 39 epoch\n",
      "[TRAIN] epoch: 040 | train acc: 95.90 | train f1: 0.9606\n",
      "[VALID] epoch: 040 | valid acc: 85.90 | valid f1: 0.8376\n",
      "Finished training 40 epoch\n",
      "[TRAIN] epoch: 041 | train acc: 94.87 | train f1: 0.9486\n",
      "[VALID] epoch: 041 | valid acc: 85.90 | valid f1: 0.8376\n",
      "Finished training 41 epoch\n",
      "[TRAIN] epoch: 042 | train acc: 95.90 | train f1: 0.9592\n",
      "[VALID] epoch: 042 | valid acc: 85.90 | valid f1: 0.8376\n",
      "Finished training 42 epoch\n",
      "[TRAIN] epoch: 043 | train acc: 95.90 | train f1: 0.9590\n",
      "[VALID] epoch: 043 | valid acc: 85.90 | valid f1: 0.8376\n",
      "Finished training 43 epoch\n",
      "[TRAIN] epoch: 044 | train acc: 96.92 | train f1: 0.9693\n",
      "[VALID] epoch: 044 | valid acc: 85.90 | valid f1: 0.8376\n",
      "Finished training 44 epoch\n",
      "[TRAIN] epoch: 045 | train acc: 94.36 | train f1: 0.9461\n",
      "[VALID] epoch: 045 | valid acc: 85.90 | valid f1: 0.8376\n",
      "Finished training 45 epoch\n",
      "[TRAIN] epoch: 046 | train acc: 95.90 | train f1: 0.9586\n",
      "[VALID] epoch: 046 | valid acc: 85.90 | valid f1: 0.8376\n",
      "Finished training 46 epoch\n",
      "[TRAIN] epoch: 047 | train acc: 96.41 | train f1: 0.9652\n",
      "[VALID] epoch: 047 | valid acc: 85.90 | valid f1: 0.8376\n",
      "Finished training 47 epoch\n",
      "[TRAIN] epoch: 048 | train acc: 97.95 | train f1: 0.9804\n",
      "[VALID] epoch: 048 | valid acc: 85.90 | valid f1: 0.8376\n",
      "Finished training 48 epoch\n",
      "[TRAIN] epoch: 049 | train acc: 96.92 | train f1: 0.9700\n",
      "[VALID] epoch: 049 | valid acc: 85.90 | valid f1: 0.8376\n",
      "Finished training 49 epoch\n",
      "[TRAIN] epoch: 050 | train acc: 93.85 | train f1: 0.9385\n",
      "[VALID] epoch: 050 | valid acc: 85.90 | valid f1: 0.8376\n",
      "Finished training 50 epoch\n"
     ]
    }
   ],
   "source": [
    "# Train the linear classifier.\n",
    "\n",
    "model.eval()\n",
    "classifier.train()\n",
    "\n",
    "best_valid_loss = np.inf\n",
    "best_classifier = None\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    total_correct = 0\n",
    "    all_outputs = []\n",
    "    all_targets = []\n",
    "\n",
    "    for step, (inp, target) in enumerate(train_loader, start=1):\n",
    "        inp = inp.to(device)\n",
    "        target = target.to(device)\n",
    "        batch_size = inp.size(0)\n",
    "\n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            if \"vit\" in MODEL_NAME:\n",
    "                intermediate_output = model.get_intermediate_layers(inp, 1)\n",
    "                output_features = torch.cat([x[:, 0] for x in intermediate_output], dim=-1)\n",
    "                avg_pooled = torch.mean(intermediate_output[-1][:, 1:], dim=1)\n",
    "                output_features = torch.cat((output_features, avg_pooled), dim=-1)\n",
    "            else:\n",
    "                output_features = model(inp)\n",
    "        output = classifier(output_features)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = nn.CrossEntropyLoss()(output, target)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate loss and samples\n",
    "        total_loss += loss.item() * batch_size\n",
    "        total_samples += batch_size\n",
    "\n",
    "        # Compute accuracy\n",
    "        _, pred = torch.max(output, dim=1)\n",
    "        total_correct += pred.eq(target).sum().item()\n",
    "\n",
    "        # Accumulate outputs and targets for F1-score computation\n",
    "        all_outputs.append(output.detach().cpu())\n",
    "        all_targets.append(target.detach().cpu())\n",
    "\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    \n",
    "    # Compute average loss and accuracy\n",
    "    avg_loss = total_loss / total_samples\n",
    "    avg_acc = 100.0 * total_correct / total_samples\n",
    "\n",
    "    # Concatenate all outputs and targets\n",
    "    all_outputs = torch.cat(all_outputs)\n",
    "    all_targets = torch.cat(all_targets)\n",
    "\n",
    "    # Compute F1-score\n",
    "    avg_f1 = utils.f1_score(all_outputs, all_targets, classifier.num_labels)\n",
    "\n",
    "    # Log statistics\n",
    "    train_stat = {\n",
    "        'epoch': epoch + 1,\n",
    "        'train_loss': avg_loss,\n",
    "        'lr': optimizer.param_groups[0][\"lr\"],\n",
    "        'train_acc1': avg_acc,\n",
    "        'train_f1': avg_f1\n",
    "    }\n",
    "\n",
    "    print(\n",
    "        \"[TRAIN] \"\n",
    "        f\"epoch: {epoch + 1:03d} | \"\n",
    "        f\"train acc: {train_stat['train_acc1']:05.2f} | \"\n",
    "        f\"train f1: {train_stat['train_f1']:.4f}\"\n",
    "    )\n",
    "\n",
    "    val_stat = validate(model, MODEL_NAME, classifier, epoch, valid_loader, device=device)\n",
    "    if val_stat['val_loss'] < best_valid_loss:\n",
    "        best_valid_loss = val_stat['val_loss']\n",
    "        best_classifier = classifier\n",
    "        classifier.to(device)\n",
    "    print(f\"Finished training {epoch + 1} epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ee8d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEST] test acc: 86.37 | test f1: 0.8707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'val_loss': 1.0286606836196703,\n",
       " 'val_acc1': 86.37435897435897,\n",
       " 'val_f1': 0.870705246925354}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test the trained linear classifier.\n",
    "\n",
    "validate(model, MODEL_NAME, best_classifier, epochs, test_loader, device=device, status=\"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
